{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Models with Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense vector word embeddings\n",
    "\n",
    "A _dense vector_ word embedding means we represent words with number-full numerical vectors-- most components are nonzero.  This is in contrast to  _sparse vector_, or bag-of-word embeddings, which have very high-dimensional vectors (the size of the vocabulary) yet with most components zero.\n",
    "\n",
    "Dense vector models also capture word meaning, such that similar words (car and automobile) have similar numerical vectors.  In a sparse vector representation, similar words probably have completely different numerical vectors.  **Dense vectors are formed as a by-product of some prediction task.**  The quality of the embedding depends on both the prediction task and the data set upon which the prediction task was trained. \n",
    "\n",
    "When we use word embeddings in our deep learning models, we refer to their birthplace as the _embedding layer_.  Sometimes, we don't actually care about the trained predictor (skip-gram and cbow models); we're just interested in the embeddings by-product for use elsewhere.  Other times, we need an embedding layer to represent words in a larger model such as a sentiment classifier; there, we may opt for pre-trained dense vectors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we don't care about the trained model and just want to create meaningful, dense word vectors, there are two popular prediction models: **skip-gram** and **CBOW** (continuous bag of words).  Word embeddings constructed in this manner are termed **word2vec** or **w2v**.  We will also look at another more recent method, **fastText**.  In any case, we've first got to construct training data from our corpus.  The exact procedure depends on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models and Training data construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for **CBOW** and **skip-gram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training corpus is a collection of sentences, Tweets, emails, comments, or even longer documents.  It is something composed of words.  Each word takes is turn being the \"target\" word, and we collect the _n_ words behind it and _n_ words which follow it.  This _n_ is referred to as **window size**.  If our example document is the sentence \"I love deep learning\" and the window size is 1, we'd get:\n",
    "  * **I**, love\n",
    "  * I, **love**, deep\n",
    "  * love, **deep**, learning\n",
    "  * deep, **learning**\n",
    "  \n",
    "The target word is bold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip-gram model training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip-gram means form word pairs with a target word and all words in the window.  These become the \"positive\" (1) samples for the skip-gram algorithm.  In our \"I love deep learning\" example we'd get (eliminating repeated pairs):\n",
    "\n",
    "  * (I, love) = 1\n",
    "  * (love, deep) = 1\n",
    "  * (deep, learning) = 1\n",
    "  \n",
    "To create negative samples (0), we pair random vocabulary words with the target word.  Yes, it's possible to unluckily pick a negative sample that usually appears around the target word.\n",
    "\n",
    "For our prediction task, we'll take the dot product of the words in each pair (a small step away from the cosine similarity).  The training will keep tweaking the word vectors to make this product as close to unity as possible for our positive samples, and zero for our negative samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happily, Keras include a function for creating skipgrams from text.  It even does the negative sampling for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1 = \"I love deep learning.\"\n",
    "text2 = \"Read Douglas Adams as much as possible.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text1, text2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2),\n",
       " ('adams', 3),\n",
       " ('i', 4),\n",
       " ('possible', 5),\n",
       " ('deep', 6),\n",
       " ('read', 7),\n",
       " ('as', 1),\n",
       " ('much', 8),\n",
       " ('douglas', 9),\n",
       " ('learning', 10)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id = tokenizer.word_index\n",
    "word2id.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note word id's are numbered from 1, not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'as',\n",
       " 2: 'love',\n",
       " 3: 'adams',\n",
       " 4: 'i',\n",
       " 5: 'possible',\n",
       " 6: 'deep',\n",
       " 7: 'read',\n",
       " 8: 'much',\n",
       " 9: 'douglas',\n",
       " 10: 'learning'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = { wordid: word for word, wordid in word2id.items()}\n",
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 6, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = [word2id[word] for word in text_to_word_sequence(text1)]\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[2, 9],\n",
       "  [6, 9],\n",
       "  [6, 3],\n",
       "  [6, 2],\n",
       "  [2, 6],\n",
       "  [2, 5],\n",
       "  [10, 2],\n",
       "  [4, 6],\n",
       "  [2, 4],\n",
       "  [10, 6],\n",
       "  [6, 10],\n",
       "  [4, 2]],\n",
       " [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg = skipgrams(encoded_text, vocabulary_size=len(word2id.keys()), window_size=1)\n",
    "sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(love,douglas)=0\n",
      "(deep,douglas)=0\n",
      "(deep,adams)=0\n",
      "(deep,love)=1\n",
      "(love,deep)=1\n",
      "(love,possible)=0\n",
      "(learning,love)=0\n",
      "(i,deep)=0\n",
      "(love,i)=1\n",
      "(learning,deep)=1\n",
      "(deep,learning)=1\n",
      "(i,love)=1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sg[0])):\n",
    "    print \"({0},{1})={2}\".format(id2word[sg[0][i][0]], id2word[sg[0][i][1]], sg[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word2id.keys())\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DENSEVEC_DIM = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.constraints import unit_norm\n",
    "from keras.layers.merge import Dot\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dense vector for each word in the pair.  The output of `Embedding` has shape `(batch_size, sequence_length, output_dim)` which in our case is `(batch_size, 1, DENSEVEC_DIM)`.  We'll use `Flatten` to get rid of that pesky middle dimension (1), so going into the dot product we'll have shape `(batch_size, DENSEVEC_DIM)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = Input(shape=(1,), dtype='int64', name='word1')\n",
    "word2 = Input(shape=(1,), dtype='int64', name='word2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_embedding = Embedding(\n",
    "    input_dim=VOCAB_SIZE+1, \n",
    "    output_dim=DENSEVEC_DIM, \n",
    "    input_length=1, \n",
    "    embeddings_constraint = unit_norm(),\n",
    "    name='shared_embedding')\n",
    "\n",
    "embedded_w1 = shared_embedding(word1)\n",
    "embedded_w2 = shared_embedding(word2)\n",
    "\n",
    "w1 = Flatten()(embedded_w1)\n",
    "w2 = Flatten()(embedded_w2)\n",
    "\n",
    "dotted = Dot(axes=1, name='dot_product')([w1, w2])\n",
    "\n",
    "prediction = Activation('sigmoid', name='output_layer')(dotted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_model = Model(inputs=[word1, word2], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sg_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can check out how the data flows through your compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x117598d50>,\n",
       " <keras.engine.topology.InputLayer at 0x1175989d0>,\n",
       " <keras.layers.embeddings.Embedding at 0x117ae2310>,\n",
       " <keras.layers.core.Flatten at 0x117aeb0d0>,\n",
       " <keras.layers.core.Flatten at 0x117aeed10>,\n",
       " <keras.layers.merge.Dot at 0x117aeecd0>,\n",
       " <keras.layers.core.Activation at 0x117accad0>]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_layer(model, num):\n",
    "    print model.layers[num]\n",
    "    print model.layers[num].input_shape\n",
    "    print model.layers[num].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.merge.Dot object at 0x117aeecd0>\n",
      "[(None, 50), (None, 50)]\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "print_layer(sg_model,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try training it with our toy data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.array(sg[0])\n",
    "targets = np.array(sg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  9],\n",
       "       [ 6,  9],\n",
       "       [ 6,  3],\n",
       "       [ 6,  2],\n",
       "       [ 2,  6],\n",
       "       [ 2,  5],\n",
       "       [10,  2],\n",
       "       [ 4,  6],\n",
       "       [ 2,  4],\n",
       "       [10,  6],\n",
       "       [ 6, 10],\n",
       "       [ 4,  2]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 6],\n",
       "       [ 2],\n",
       "       [ 2],\n",
       "       [10],\n",
       "       [ 4],\n",
       "       [ 2],\n",
       "       [10],\n",
       "       [ 6],\n",
       "       [ 4]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_list = np.reshape(pairs[:, 0], (len(pairs), 1))\n",
    "w1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9],\n",
       "       [ 9],\n",
       "       [ 3],\n",
       "       [ 2],\n",
       "       [ 6],\n",
       "       [ 5],\n",
       "       [ 2],\n",
       "       [ 6],\n",
       "       [ 4],\n",
       "       [ 6],\n",
       "       [10],\n",
       "       [ 2]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_list = np.reshape(pairs[:, 1], (len(pairs), 1))\n",
    "w2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_list.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s - loss: 0.0126\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s - loss: 0.0125\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s - loss: 0.0125\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s - loss: 0.0124\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s - loss: 0.0123\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s - loss: 0.0123\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s - loss: 0.0122\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s - loss: 0.0122\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s - loss: 0.0121\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s - loss: 0.0120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117f05e90>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_model.fit(x=[w1_list, w2_list], y=targets,  epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Bag of Words (CBOW) model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW means we take _all_ the words in the window and use them to predict the target word.  Note we are trying to predict an actual word (or a probability distribution over words) with CBOW, whereas in skip-gram we are trying to predict a similarity score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText is creating dense document vectors using the words in the document enhanced with n-grams.  These are embedded, averaged, and fed through a hidden dense layer, with a sigmoid activation.  The prediction task is some binary classification of the documents.  As usual, after training we can extract the dense vectors from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText Model Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 20000  # number of unique words in the dataset\n",
    "MAXLEN = 400  # max word (feature) length of a review  \n",
    "EMBEDDING_DIMS = 50\n",
    "NGRAM_RANGE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data prep functions lifted from the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2), (2, 3), (3, 4), (4, 5)}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ngram_set([1, 2, 3, 4, 5], ngram_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2, 3), (2, 3, 4), (3, 4, 5)}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ngram_set([1, 2, 3, 4, 5], ngram_value=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for i in range(len(new_list) - ngram_range + 1):\n",
    "            for ngram_value in range(2, ngram_range + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    new_list.append(token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = [[1,2,3,4,5], [6,7,8]]\n",
    "token_indice = {(1,2): 20000, (4,5): 20001, (6,7,8): 20002}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 20000, 20001], [6, 7, 8]]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_ngram(sequences, token_indice, ngram_range=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 20000], [6, 7, 8, 20002]]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_ngram(sequences, token_indice, ngram_range=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load canned training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add n-gram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_set = set()\n",
    "for input_list in x_train:\n",
    "    for i in range(2, NGRAM_RANGE + 1):\n",
    "        set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "        ngram_set.update(set_of_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185229"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngram_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign id's to the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_index = MAX_FEATURES + 1\n",
    "token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "indice_token = {token_indice[k]: k for k in token_indice}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update MAX_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205230"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_FEATURES = np.max(list(indice_token.keys())) + 1\n",
    "MAX_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add n-grams to the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = add_ngram(x_train, token_indice, NGRAM_RANGE)\n",
    "x_test = add_ngram(x_test, token_indice, NGRAM_RANGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all input sequences the same length by padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 2, 3, 4, 5],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 6, 7, 8]], dtype=int32)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.pad_sequences([[1,2,3,4,5], [6,7,8]], maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=MAXLEN)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 400)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 400)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = Sequential()\n",
    "\n",
    "ft_model.add(Embedding(\n",
    "    input_dim = MAX_FEATURES,\n",
    "    output_dim = EMBEDDING_DIMS,\n",
    "    input_length= MAXLEN))\n",
    "\n",
    "ft_model.add(GlobalAveragePooling1D())\n",
    "\n",
    "ft_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x117f12650>,\n",
       " <keras.layers.pooling.GlobalAveragePooling1D at 0x117bc51d0>,\n",
       " <keras.layers.core.Dense at 0x1190c3dd0>]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.embeddings.Embedding object at 0x117f12650>\n",
      "(None, 400)\n",
      "(None, 400, 50)\n"
     ]
    }
   ],
   "source": [
    "print_layer(ft_model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.pooling.GlobalAveragePooling1D object at 0x117bc51d0>\n",
      "(None, 400, 50)\n",
      "(None, 50)\n"
     ]
    }
   ],
   "source": [
    "print_layer(ft_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x1190c3dd0>\n",
      "(None, 50)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "print_layer(ft_model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 212s - loss: 0.6614 - acc: 0.7317 - val_loss: 0.6059 - val_acc: 0.8069\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 210s - loss: 0.5023 - acc: 0.8827 - val_loss: 0.4631 - val_acc: 0.8567\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 207s - loss: 0.3363 - acc: 0.9321 - val_loss: 0.3735 - val_acc: 0.8788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129d7bbd0>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.fit(x_train, y_train, batch_size=100, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our own data download and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the [Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/) for our corpus.  While Keras has its own data samples you can import for modeling (including this one), I think it's very important to get and process your own data.  Otherwise, the results appear to materialize out of thin air and it's more difficult to get on with your own research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/Users/pfigliozzi/aclImdb/train/unsup\"\n",
    "files = glob.glob(datapath+\"/*.txt\")[:1000] #first 1000 (there are 50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_table(filename, header=None, names=['raw']) for filename in files], ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x107ee6710>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105edc890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.raw.map(lambda x: len(x)).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000. * 2000. / 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
